{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# End-to-End Insurance Risk Analytics\n",
    "## Task 1.2: Exploratory Data Analysis (EDA) & Statistical Analysis\n",
    "\n",
    "### Project Overview\n",
    "This notebook performs comprehensive exploratory data analysis on insurance data to:\n",
    "- Develop foundational understanding of the data\n",
    "- Assess data quality and uncover patterns in risk and profitability\n",
    "- Answer key business questions about loss ratios, claim patterns, and risk factors\n",
    "\n",
    "### Data Period: February 2014 to August 2015\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, jarque_bera, skew, kurtosis\n",
    "import plotly.io as pio\n",
    "\n",
    "# Set up plotting parameters\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "Let's start by loading the insurance dataset and understanding its structure. Given the large size of the data (505MB), we'll work with a representative sample for efficient analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/MachineLearningRating_v3.txt'\n",
    "\n",
    "# First, let's check the file size and determine sampling strategy\n",
    "import os\n",
    "file_size = os.path.getsize(data_path) / (1024 * 1024)  # Size in MB\n",
    "print(f\"File size: {file_size:.2f} MB\")\n",
    "\n",
    "# Read a sample of the data for initial exploration\n",
    "# We'll use every nth row to get a representative sample\n",
    "sample_size = 100000  # Sample size for analysis\n",
    "print(f\"Loading sample of {sample_size:,} rows for analysis...\")\n",
    "\n",
    "# Read the data with pipe delimiter\n",
    "df_sample = pd.read_csv(data_path, delimiter='|', nrows=sample_size)\n",
    "\n",
    "print(f\"Sample loaded successfully!\")\n",
    "print(f\"Dataset shape: {df_sample.shape}\")\n",
    "print(f\"Sample represents approximately {(sample_size / (file_size * 1024 * 20)) * 100:.2f}% of the full dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset shape: {df_sample.shape}\")\n",
    "print(f\"Columns: {df_sample.shape[1]}\")\n",
    "print(f\"Rows in sample: {df_sample.shape[0]:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMN NAMES AND DATA TYPES\")\n",
    "print(\"=\"*60)\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIRST FEW ROWS\")\n",
    "print(\"=\"*60)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Data Structure Review and Preprocessing\n",
    "\n",
    "Let's examine the data structure more closely and prepare it for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for processing\n",
    "df = df_sample.copy()\n",
    "\n",
    "# Convert TransactionMonth to datetime\n",
    "df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "\n",
    "# Create additional date features for analysis\n",
    "df['Year'] = df['TransactionMonth'].dt.year\n",
    "df['Month'] = df['TransactionMonth'].dt.month\n",
    "df['Quarter'] = df['TransactionMonth'].dt.quarter\n",
    "\n",
    "# Calculate Loss Ratio (Key KPI)\n",
    "df['LossRatio'] = np.where(df['TotalPremium'] > 0, \n",
    "                          df['TotalClaims'] / df['TotalPremium'], \n",
    "                          np.nan)\n",
    "\n",
    "# Identify key column categories for organized analysis\n",
    "policy_columns = ['UnderwrittenCoverID', 'PolicyID']\n",
    "client_columns = ['IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', \n",
    "                 'Bank', 'AccountType', 'MaritalStatus', 'Gender']\n",
    "location_columns = ['Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone']\n",
    "vehicle_columns = ['ItemType', 'mmcode', 'VehicleType', 'RegistrationYear', 'make', 'Model',\n",
    "                  'Cylinders', 'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
    "                  'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser', 'TrackingDevice',\n",
    "                  'CapitalOutstanding', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted',\n",
    "                  'CrossBorder', 'NumberOfVehiclesInFleet']\n",
    "plan_columns = ['SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm', 'ExcessSelected',\n",
    "               'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product',\n",
    "               'StatutoryClass', 'StatutoryRiskType']\n",
    "financial_columns = ['TotalPremium', 'TotalClaims', 'LossRatio']\n",
    "\n",
    "print(\"Data preprocessing completed!\")\n",
    "print(f\"Dataset covers period: {df['TransactionMonth'].min()} to {df['TransactionMonth'].max()}\")\n",
    "print(f\"Total months covered: {df['TransactionMonth'].nunique()}\")\n",
    "print(f\"Unique policies: {df['PolicyID'].nunique():,}\")\n",
    "print(f\"Average Loss Ratio: {df['LossRatio'].mean():.4f}\")\n",
    "print(f\"Loss Ratio calculated for {df['LossRatio'].notna().sum():,} records\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Data Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "# Create a comprehensive missing data report\n",
    "missing_report = pd.DataFrame({\n",
    "    'Column': missing_data.index,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Columns with missing data: {(missing_data > 0).sum()}\")\n",
    "print(f\"Total missing values: {missing_data.sum():,}\")\n",
    "\n",
    "print(\"\\nTop 15 columns with highest missing percentages:\")\n",
    "print(missing_report.head(15).to_string(index=False))\n",
    "\n",
    "# Check for columns with all missing values\n",
    "all_missing = missing_report[missing_report['Missing_Percentage'] == 100.0]\n",
    "if not all_missing.empty:\n",
    "    print(f\"\\nColumns with 100% missing data: {len(all_missing)}\")\n",
    "    print(all_missing['Column'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data quality for key financial variables\n",
    "print(\"=\"*60)\n",
    "print(\"FINANCIAL VARIABLES DATA QUALITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "financial_vars = ['TotalPremium', 'TotalClaims', 'LossRatio']\n",
    "for var in financial_vars:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(f\"  Missing values: {df[var].isnull().sum():,} ({(df[var].isnull().sum()/len(df)*100):.2f}%)\")\n",
    "        print(f\"  Zero values: {(df[var] == 0).sum():,} ({((df[var] == 0).sum()/len(df)*100):.2f}%)\")\n",
    "        print(f\"  Negative values: {(df[var] < 0).sum():,} ({((df[var] < 0).sum()/len(df)*100):.2f}%)\")\n",
    "        if df[var].dtype in ['int64', 'float64']:\n",
    "            print(f\"  Min: {df[var].min():.2f}\")\n",
    "            print(f\"  Max: {df[var].max():.2f}\")\n",
    "            print(f\"  Mean: {df[var].mean():.2f}\")\n",
    "            print(f\"  Median: {df[var].median():.2f}\")\n",
    "\n",
    "# Check for data consistency\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CONSISTENCY CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if TotalClaims > TotalPremium (extreme loss ratios)\n",
    "extreme_loss = df[df['TotalClaims'] > df['TotalPremium']]\n",
    "print(f\"Records with TotalClaims > TotalPremium: {len(extreme_loss):,} ({len(extreme_loss)/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Check for unrealistic registration years\n",
    "current_year = datetime.now().year\n",
    "unrealistic_years = df[(df['RegistrationYear'] < 1900) | (df['RegistrationYear'] > current_year)]\n",
    "print(f\"Records with unrealistic RegistrationYear: {len(unrealistic_years):,}\")\n",
    "\n",
    "# Check for missing gender/province data\n",
    "key_categorical = ['Gender', 'Province', 'VehicleType']\n",
    "for col in key_categorical:\n",
    "    if col in df.columns:\n",
    "        missing_or_empty = df[col].isnull() | (df[col] == '') | (df[col] == ' ')\n",
    "        print(f\"{col} missing/empty: {missing_or_empty.sum():,} ({missing_or_empty.sum()/len(df)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Descriptive Statistics and Data Summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive descriptive statistics for numerical variables\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS FOR NUMERICAL VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "desc_stats = df[numerical_columns].describe()\n",
    "print(desc_stats)\n",
    "\n",
    "# Focus on key financial metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINANCIAL METRICS - DETAILED STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "key_financial = ['TotalPremium', 'TotalClaims', 'LossRatio', 'CustomValueEstimate', 'SumInsured']\n",
    "available_financial = [col for col in key_financial if col in df.columns]\n",
    "\n",
    "for col in available_financial:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Count: {df[col].count():,}\")\n",
    "    print(f\"  Mean: {df[col].mean():.4f}\")\n",
    "    print(f\"  Std: {df[col].std():.4f}\")\n",
    "    print(f\"  Min: {df[col].min():.4f}\")\n",
    "    print(f\"  25%: {df[col].quantile(0.25):.4f}\")\n",
    "    print(f\"  50% (Median): {df[col].median():.4f}\")\n",
    "    print(f\"  75%: {df[col].quantile(0.75):.4f}\")\n",
    "    print(f\"  Max: {df[col].max():.4f}\")\n",
    "    print(f\"  Skewness: {skew(df[col].dropna()):.4f}\")\n",
    "    print(f\"  Kurtosis: {kurtosis(df[col].dropna()):.4f}\")\n",
    "    \n",
    "    # Calculate coefficient of variation\n",
    "    cv = df[col].std() / df[col].mean() if df[col].mean() != 0 else np.nan\n",
    "    print(f\"  Coefficient of Variation: {cv:.4f}\")\n",
    "    \n",
    "    # Identify potential outliers using IQR method\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f\"  Potential outliers (IQR method): {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables analysis\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CATEGORICAL VARIABLES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "key_categorical = ['Province', 'Gender', 'VehicleType', 'make', 'CoverType', 'CoverGroup']\n",
    "available_categorical = [col for col in key_categorical if col in df.columns]\n",
    "\n",
    "for col in available_categorical:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Most common values:\")\n",
    "    value_counts = df[col].value_counts().head(5)\n",
    "    for value, count in value_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"    {value}: {count:,} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for potential data quality issues\n",
    "    if col in ['Gender', 'Province']:\n",
    "        unique_vals = df[col].unique()\n",
    "        print(f\"  All unique values: {sorted([str(val) for val in unique_vals if pd.notna(val)])}\")\n",
    "\n",
    "# Business-relevant aggregations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS INSIGHTS - LOSS RATIO ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall Loss Ratio\n",
    "overall_loss_ratio = df['LossRatio'].mean()\n",
    "print(f\"Overall Portfolio Loss Ratio: {overall_loss_ratio:.4f}\")\n",
    "\n",
    "# Loss Ratio by Province\n",
    "if 'Province' in df.columns:\n",
    "    print(\"\\nLoss Ratio by Province:\")\n",
    "    province_lr = df.groupby('Province').agg({\n",
    "        'LossRatio': ['mean', 'count'],\n",
    "        'TotalPremium': 'sum',\n",
    "        'TotalClaims': 'sum'\n",
    "    }).round(4)\n",
    "    province_lr.columns = ['AvgLossRatio', 'PolicyCount', 'TotalPremium', 'TotalClaims']\n",
    "    province_lr['ActualLossRatio'] = province_lr['TotalClaims'] / province_lr['TotalPremium']\n",
    "    province_lr = province_lr.sort_values('ActualLossRatio', ascending=False)\n",
    "    print(province_lr.head(10))\n",
    "\n",
    "# Loss Ratio by Vehicle Type\n",
    "if 'VehicleType' in df.columns:\n",
    "    print(\"\\nLoss Ratio by Vehicle Type:\")\n",
    "    vehicle_lr = df.groupby('VehicleType').agg({\n",
    "        'LossRatio': ['mean', 'count'],\n",
    "        'TotalPremium': 'sum',\n",
    "        'TotalClaims': 'sum'\n",
    "    }).round(4)\n",
    "    vehicle_lr.columns = ['AvgLossRatio', 'PolicyCount', 'TotalPremium', 'TotalClaims']\n",
    "    vehicle_lr['ActualLossRatio'] = vehicle_lr['TotalClaims'] / vehicle_lr['TotalPremium']\n",
    "    vehicle_lr = vehicle_lr.sort_values('ActualLossRatio', ascending=False)\n",
    "    print(vehicle_lr)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Univariate Analysis - Distribution of Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis for key financial variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Distribution of Key Financial Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "# TotalPremium distribution\n",
    "axes[0, 0].hist(df['TotalPremium'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Total Premium')\n",
    "axes[0, 0].set_xlabel('Total Premium')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['TotalPremium'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"TotalPremium\"].mean():.2f}')\n",
    "axes[0, 0].axvline(df['TotalPremium'].median(), color='green', linestyle='--', label=f'Median: {df[\"TotalPremium\"].median():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# TotalClaims distribution\n",
    "axes[0, 1].hist(df['TotalClaims'], bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Total Claims')\n",
    "axes[0, 1].set_xlabel('Total Claims')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df['TotalClaims'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"TotalClaims\"].mean():.2f}')\n",
    "axes[0, 1].axvline(df['TotalClaims'].median(), color='green', linestyle='--', label=f'Median: {df[\"TotalClaims\"].median():.2f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# LossRatio distribution (filtered to remove extreme outliers for visualization)\n",
    "loss_ratio_filtered = df['LossRatio'][(df['LossRatio'] >= 0) & (df['LossRatio'] <= 5)]\n",
    "axes[1, 0].hist(loss_ratio_filtered, bins=50, alpha=0.7, color='gold', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution of Loss Ratio (0-5 range)')\n",
    "axes[1, 0].set_xlabel('Loss Ratio')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(loss_ratio_filtered.mean(), color='red', linestyle='--', label=f'Mean: {loss_ratio_filtered.mean():.4f}')\n",
    "axes[1, 0].axvline(loss_ratio_filtered.median(), color='green', linestyle='--', label=f'Median: {loss_ratio_filtered.median():.4f}')\n",
    "axes[1, 0].axvline(1.0, color='orange', linestyle='-', linewidth=2, label='Break-even (1.0)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# CustomValueEstimate distribution (log scale for better visualization)\n",
    "if 'CustomValueEstimate' in df.columns:\n",
    "    cve_positive = df['CustomValueEstimate'][df['CustomValueEstimate'] > 0]\n",
    "    axes[1, 1].hist(np.log10(cve_positive), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[1, 1].set_title('Distribution of Custom Value Estimate (Log10 Scale)')\n",
    "    axes[1, 1].set_xlabel('Log10(Custom Value Estimate)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for normality\n",
    "print(\"=\"*60)\n",
    "print(\"NORMALITY TESTS FOR KEY FINANCIAL VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in ['TotalPremium', 'TotalClaims', 'LossRatio']:\n",
    "    if col in df.columns:\n",
    "        data = df[col].dropna()\n",
    "        if len(data) > 8:  # Minimum sample size for Jarque-Bera test\n",
    "            # Jarque-Bera test\n",
    "            jb_stat, jb_p = jarque_bera(data)\n",
    "            \n",
    "            # Shapiro-Wilk test (use a sample if data is too large)\n",
    "            if len(data) > 5000:\n",
    "                sample_data = data.sample(5000, random_state=42)\n",
    "            else:\n",
    "                sample_data = data\n",
    "            \n",
    "            shapiro_stat, shapiro_p = stats.shapiro(sample_data)\n",
    "            \n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Jarque-Bera test: statistic={jb_stat:.4f}, p-value={jb_p:.4f}\")\n",
    "            print(f\"  Shapiro-Wilk test: statistic={shapiro_stat:.4f}, p-value={shapiro_p:.4f}\")\n",
    "            \n",
    "            if jb_p < 0.05:\n",
    "                print(f\"  JB Result: NOT normally distributed (p < 0.05)\")\n",
    "            else:\n",
    "                print(f\"  JB Result: Possibly normally distributed (p >= 0.05)\")\n",
    "                \n",
    "            if shapiro_p < 0.05:\n",
    "                print(f\"  SW Result: NOT normally distributed (p < 0.05)\")\n",
    "            else:\n",
    "                print(f\"  SW Result: Possibly normally distributed (p >= 0.05)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Distribution of Key Categorical Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Province distribution\n",
    "if 'Province' in df.columns:\n",
    "    province_counts = df['Province'].value_counts().head(10)\n",
    "    axes[0, 0].bar(range(len(province_counts)), province_counts.values, color='lightblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Top 10 Provinces by Policy Count')\n",
    "    axes[0, 0].set_xlabel('Province')\n",
    "    axes[0, 0].set_ylabel('Number of Policies')\n",
    "    axes[0, 0].set_xticks(range(len(province_counts)))\n",
    "    axes[0, 0].set_xticklabels(province_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# Gender distribution\n",
    "if 'Gender' in df.columns:\n",
    "    gender_counts = df['Gender'].value_counts()\n",
    "    axes[0, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightblue', 'lightgreen', 'gold'])\n",
    "    axes[0, 1].set_title('Gender Distribution')\n",
    "\n",
    "# Vehicle Type distribution\n",
    "if 'VehicleType' in df.columns:\n",
    "    vehicle_counts = df['VehicleType'].value_counts()\n",
    "    axes[1, 0].bar(range(len(vehicle_counts)), vehicle_counts.values, color='lightgreen', edgecolor='black')\n",
    "    axes[1, 0].set_title('Vehicle Type Distribution')\n",
    "    axes[1, 0].set_xlabel('Vehicle Type')\n",
    "    axes[1, 0].set_ylabel('Number of Policies')\n",
    "    axes[1, 0].set_xticks(range(len(vehicle_counts)))\n",
    "    axes[1, 0].set_xticklabels(vehicle_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# Top vehicle makes\n",
    "if 'make' in df.columns:\n",
    "    make_counts = df['make'].value_counts().head(10)\n",
    "    axes[1, 1].barh(range(len(make_counts)), make_counts.values, color='gold', edgecolor='black')\n",
    "    axes[1, 1].set_title('Top 10 Vehicle Makes')\n",
    "    axes[1, 1].set_xlabel('Number of Policies')\n",
    "    axes[1, 1].set_ylabel('Vehicle Make')\n",
    "    axes[1, 1].set_yticks(range(len(make_counts)))\n",
    "    axes[1, 1].set_yticklabels(make_counts.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional insights on key categorical variables\n",
    "print(\"=\"*60)\n",
    "print(\"CATEGORICAL VARIABLES DETAILED ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze concentration in categorical variables\n",
    "key_cats = ['Province', 'Gender', 'VehicleType', 'make']\n",
    "available_cats = [col for col in key_cats if col in df.columns]\n",
    "\n",
    "for col in available_cats:\n",
    "    print(f\"\\n{col.upper()} Analysis:\")\n",
    "    value_counts = df[col].value_counts()\n",
    "    print(f\"  Total unique values: {len(value_counts)}\")\n",
    "    print(f\"  Top value concentration: {value_counts.iloc[0] / len(df) * 100:.2f}% ({value_counts.index[0]})\")\n",
    "    print(f\"  Top 3 values cover: {value_counts.head(3).sum() / len(df) * 100:.2f}% of data\")\n",
    "    \n",
    "    # Calculate Herfindahl-Hirschman Index (concentration measure)\n",
    "    proportions = value_counts / len(df)\n",
    "    hhi = (proportions ** 2).sum()\n",
    "    print(f\"  HHI (concentration index): {hhi:.4f} (closer to 1 = more concentrated)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Bivariate and Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical variables\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove date-related columns for correlation analysis\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['Year', 'Month', 'Quarter']]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Show only lower triangle\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Numerical Variables', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify strongest correlations\n",
    "print(\"=\"*60)\n",
    "print(\"STRONGEST CORRELATIONS (excluding self-correlations)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find pairs with high correlation\n",
    "high_corr_pairs = []\n",
    "for col in upper_tri.columns:\n",
    "    for idx in upper_tri.index:\n",
    "        value = upper_tri.loc[idx, col]\n",
    "        if not pd.isna(value) and abs(value) > 0.3:  # Threshold for \"strong\" correlation\n",
    "            high_corr_pairs.append((idx, col, value))\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(\"Top 10 strongest correlations:\")\n",
    "for i, (var1, var2, corr_val) in enumerate(high_corr_pairs[:10]):\n",
    "    print(f\"{i+1:2d}. {var1} - {var2}: {corr_val:.4f}\")\n",
    "\n",
    "# Focus on correlations with key business metrics\n",
    "key_metrics = ['TotalPremium', 'TotalClaims', 'LossRatio']\n",
    "print(f\"\\nCorrelations with key business metrics:\")\n",
    "for metric in key_metrics:\n",
    "    if metric in corr_matrix.columns:\n",
    "        metric_corrs = corr_matrix[metric].abs().sort_values(ascending=False)\n",
    "        print(f\"\\n{metric} - Top 5 correlations:\")\n",
    "        for var, corr_val in metric_corrs.head(6).items():  # Top 6 (including self)\n",
    "            if var != metric:  # Exclude self-correlation\n",
    "                print(f\"  {var}: {corr_matrix[metric][var]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for key relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Key Bivariate Relationships', fontsize=16, fontweight='bold')\n",
    "\n",
    "# TotalPremium vs TotalClaims\n",
    "axes[0, 0].scatter(df['TotalPremium'], df['TotalClaims'], alpha=0.5, s=10)\n",
    "axes[0, 0].set_xlabel('Total Premium')\n",
    "axes[0, 0].set_ylabel('Total Claims')\n",
    "axes[0, 0].set_title('Total Premium vs Total Claims')\n",
    "# Add break-even line\n",
    "max_val = max(df['TotalPremium'].max(), df['TotalClaims'].max())\n",
    "axes[0, 0].plot([0, max_val], [0, max_val], 'r--', label='Break-even line')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# CustomValueEstimate vs TotalPremium\n",
    "if 'CustomValueEstimate' in df.columns:\n",
    "    valid_data = df[(df['CustomValueEstimate'] > 0) & (df['TotalPremium'] > 0)]\n",
    "    axes[0, 1].scatter(valid_data['CustomValueEstimate'], valid_data['TotalPremium'], alpha=0.5, s=10)\n",
    "    axes[0, 1].set_xlabel('Custom Value Estimate')\n",
    "    axes[0, 1].set_ylabel('Total Premium')\n",
    "    axes[0, 1].set_title('Custom Value Estimate vs Total Premium')\n",
    "\n",
    "# RegistrationYear vs LossRatio\n",
    "if 'RegistrationYear' in df.columns:\n",
    "    valid_data = df[(df['RegistrationYear'] > 1990) & (df['LossRatio'].notna()) & (df['LossRatio'] >= 0) & (df['LossRatio'] <= 5)]\n",
    "    axes[1, 0].scatter(valid_data['RegistrationYear'], valid_data['LossRatio'], alpha=0.5, s=10)\n",
    "    axes[1, 0].set_xlabel('Registration Year')\n",
    "    axes[1, 0].set_ylabel('Loss Ratio')\n",
    "    axes[1, 0].set_title('Registration Year vs Loss Ratio')\n",
    "    axes[1, 0].axhline(y=1.0, color='r', linestyle='--', label='Break-even')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# SumInsured vs TotalPremium\n",
    "if 'SumInsured' in df.columns:\n",
    "    valid_data = df[(df['SumInsured'] > 0) & (df['TotalPremium'] > 0)]\n",
    "    axes[1, 1].scatter(valid_data['SumInsured'], valid_data['TotalPremium'], alpha=0.5, s=10)\n",
    "    axes[1, 1].set_xlabel('Sum Insured')\n",
    "    axes[1, 1].set_ylabel('Total Premium')\n",
    "    axes[1, 1].set_title('Sum Insured vs Total Premium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical analysis of relationships\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTICAL ANALYSIS OF KEY RELATIONSHIPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate correlation coefficients for key pairs\n",
    "key_pairs = [\n",
    "    ('TotalPremium', 'TotalClaims'),\n",
    "    ('CustomValueEstimate', 'TotalPremium'),\n",
    "    ('SumInsured', 'TotalPremium'),\n",
    "    ('RegistrationYear', 'LossRatio')\n",
    "]\n",
    "\n",
    "for var1, var2 in key_pairs:\n",
    "    if var1 in df.columns and var2 in df.columns:\n",
    "        # Remove missing values and outliers\n",
    "        valid_data = df[[var1, var2]].dropna()\n",
    "        \n",
    "        if len(valid_data) > 10:\n",
    "            # Pearson correlation\n",
    "            pearson_corr, pearson_p = stats.pearsonr(valid_data[var1], valid_data[var2])\n",
    "            \n",
    "            # Spearman correlation (rank-based, less sensitive to outliers)\n",
    "            spearman_corr, spearman_p = stats.spearmanr(valid_data[var1], valid_data[var2])\n",
    "            \n",
    "            print(f\"\\n{var1} vs {var2}:\")\n",
    "            print(f\"  Sample size: {len(valid_data):,}\")\n",
    "            print(f\"  Pearson correlation: {pearson_corr:.4f} (p-value: {pearson_p:.4f})\")\n",
    "            print(f\"  Spearman correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4f})\")\n",
    "            \n",
    "            if pearson_p < 0.05:\n",
    "                print(f\"  Result: Statistically significant linear relationship\")\n",
    "            else:\n",
    "                print(f\"  Result: No statistically significant linear relationship\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Temporal Trends Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis of key metrics\n",
    "# Aggregate data by month\n",
    "monthly_trends = df.groupby('TransactionMonth').agg({\n",
    "    'TotalPremium': ['sum', 'mean', 'count'],\n",
    "    'TotalClaims': ['sum', 'mean'],\n",
    "    'LossRatio': 'mean',\n",
    "    'PolicyID': 'nunique'\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "monthly_trends.columns = ['_'.join(col).strip() for col in monthly_trends.columns.values]\n",
    "monthly_trends = monthly_trends.reset_index()\n",
    "\n",
    "# Calculate monthly loss ratio based on totals\n",
    "monthly_trends['Monthly_LossRatio'] = monthly_trends['TotalClaims_sum'] / monthly_trends['TotalPremium_sum']\n",
    "\n",
    "# Create temporal visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Temporal Trends in Insurance Metrics (Feb 2014 - Aug 2015)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Total Premium over time\n",
    "axes[0, 0].plot(monthly_trends['TransactionMonth'], monthly_trends['TotalPremium_sum'], marker='o', linewidth=2, markersize=6)\n",
    "axes[0, 0].set_title('Total Monthly Premium')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Total Premium')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Total Claims over time\n",
    "axes[0, 1].plot(monthly_trends['TransactionMonth'], monthly_trends['TotalClaims_sum'], marker='o', linewidth=2, markersize=6, color='red')\n",
    "axes[0, 1].set_title('Total Monthly Claims')\n",
    "axes[0, 1].set_xlabel('Month')\n",
    "axes[0, 1].set_ylabel('Total Claims')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly Loss Ratio\n",
    "axes[1, 0].plot(monthly_trends['TransactionMonth'], monthly_trends['Monthly_LossRatio'], marker='o', linewidth=2, markersize=6, color='green')\n",
    "axes[1, 0].axhline(y=1.0, color='orange', linestyle='--', linewidth=2, label='Break-even (1.0)')\n",
    "axes[1, 0].set_title('Monthly Loss Ratio')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Loss Ratio')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Policy Count over time\n",
    "axes[1, 1].plot(monthly_trends['TransactionMonth'], monthly_trends['TotalPremium_count'], marker='o', linewidth=2, markersize=6, color='purple')\n",
    "axes[1, 1].set_title('Monthly Policy Count')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Number of Policies')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print temporal insights\n",
    "print(\"=\"*60)\n",
    "print(\"TEMPORAL TRENDS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Analysis Period: {monthly_trends['TransactionMonth'].min().strftime('%B %Y')} to {monthly_trends['TransactionMonth'].max().strftime('%B %Y')}\")\n",
    "print(f\"Total months analyzed: {len(monthly_trends)}\")\n",
    "\n",
    "# Calculate trend statistics\n",
    "print(f\"\\nTREND STATISTICS:\")\n",
    "print(f\"Average monthly premium: {monthly_trends['TotalPremium_sum'].mean():,.2f}\")\n",
    "print(f\"Premium growth (first to last month): {((monthly_trends['TotalPremium_sum'].iloc[-1] / monthly_trends['TotalPremium_sum'].iloc[0]) - 1) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average monthly claims: {monthly_trends['TotalClaims_sum'].mean():,.2f}\")\n",
    "print(f\"Claims growth (first to last month): {((monthly_trends['TotalClaims_sum'].iloc[-1] / monthly_trends['TotalClaims_sum'].iloc[0]) - 1) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average monthly loss ratio: {monthly_trends['Monthly_LossRatio'].mean():.4f}\")\n",
    "print(f\"Best month (lowest loss ratio): {monthly_trends.loc[monthly_trends['Monthly_LossRatio'].idxmin(), 'TransactionMonth'].strftime('%B %Y')} ({monthly_trends['Monthly_LossRatio'].min():.4f})\")\n",
    "print(f\"Worst month (highest loss ratio): {monthly_trends.loc[monthly_trends['Monthly_LossRatio'].idxmax(), 'TransactionMonth'].strftime('%B %Y')} ({monthly_trends['Monthly_LossRatio'].max():.4f})\")\n",
    "\n",
    "# Seasonal analysis\n",
    "monthly_trends['Month_Name'] = monthly_trends['TransactionMonth'].dt.month_name()\n",
    "seasonal_analysis = monthly_trends.groupby('Month_Name').agg({\n",
    "    'Monthly_LossRatio': ['mean', 'count'],\n",
    "    'TotalPremium_sum': 'mean',\n",
    "    'TotalClaims_sum': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(f\"\\nSEASONAL PATTERNS:\")\n",
    "print(\"Average Loss Ratio by Month:\")\n",
    "for month, data in seasonal_analysis.iterrows():\n",
    "    print(f\"  {month}: {data[('Monthly_LossRatio', 'mean')]:.4f}\")\n",
    "\n",
    "# Identify months with loss ratio > 1.0\n",
    "unprofitable_months = monthly_trends[monthly_trends['Monthly_LossRatio'] > 1.0]\n",
    "print(f\"\\nUNPROFITABLE MONTHS (Loss Ratio > 1.0): {len(unprofitable_months)} out of {len(monthly_trends)}\")\n",
    "if len(unprofitable_months) > 0:\n",
    "    print(\"Months with losses:\")\n",
    "    for _, month_data in unprofitable_months.iterrows():\n",
    "        print(f\"  {month_data['TransactionMonth'].strftime('%B %Y')}: {month_data['Monthly_LossRatio']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Geographical Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical analysis by Province\n",
    "province_analysis = df.groupby('Province').agg({\n",
    "    'TotalPremium': ['sum', 'mean', 'count'],\n",
    "    'TotalClaims': ['sum', 'mean'],\n",
    "    'LossRatio': 'mean',\n",
    "    'CustomValueEstimate': 'mean',\n",
    "    'PolicyID': 'nunique'\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "province_analysis.columns = ['_'.join(col).strip() for col in province_analysis.columns.values]\n",
    "province_analysis = province_analysis.reset_index()\n",
    "\n",
    "# Calculate actual loss ratio by province\n",
    "province_analysis['Actual_LossRatio'] = province_analysis['TotalClaims_sum'] / province_analysis['TotalPremium_sum']\n",
    "province_analysis['Premium_Market_Share'] = (province_analysis['TotalPremium_sum'] / province_analysis['TotalPremium_sum'].sum()) * 100\n",
    "\n",
    "# Sort by loss ratio for analysis\n",
    "province_analysis_sorted = province_analysis.sort_values('Actual_LossRatio', ascending=False)\n",
    "\n",
    "# Visualization of geographical patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Geographical Analysis by Province', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Loss ratio by province\n",
    "axes[0, 0].bar(range(len(province_analysis_sorted)), province_analysis_sorted['Actual_LossRatio'], \n",
    "               color=['red' if x > 1.0 else 'green' for x in province_analysis_sorted['Actual_LossRatio']], \n",
    "               edgecolor='black')\n",
    "axes[0, 0].axhline(y=1.0, color='orange', linestyle='--', linewidth=2, label='Break-even')\n",
    "axes[0, 0].set_title('Loss Ratio by Province')\n",
    "axes[0, 0].set_xlabel('Province')\n",
    "axes[0, 0].set_ylabel('Loss Ratio')\n",
    "axes[0, 0].set_xticks(range(len(province_analysis_sorted)))\n",
    "axes[0, 0].set_xticklabels(province_analysis_sorted['Province'], rotation=45, ha='right')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Premium volume by province\n",
    "top_provinces_premium = province_analysis.nlargest(10, 'TotalPremium_sum')\n",
    "axes[0, 1].bar(range(len(top_provinces_premium)), top_provinces_premium['TotalPremium_sum'], \n",
    "               color='lightblue', edgecolor='black')\n",
    "axes[0, 1].set_title('Top 10 Provinces by Total Premium Volume')\n",
    "axes[0, 1].set_xlabel('Province')\n",
    "axes[0, 1].set_ylabel('Total Premium')\n",
    "axes[0, 1].set_xticks(range(len(top_provinces_premium)))\n",
    "axes[0, 1].set_xticklabels(top_provinces_premium['Province'], rotation=45, ha='right')\n",
    "\n",
    "# Policy count by province\n",
    "top_provinces_count = province_analysis.nlargest(10, 'TotalPremium_count')\n",
    "axes[1, 0].bar(range(len(top_provinces_count)), top_provinces_count['TotalPremium_count'], \n",
    "               color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Top 10 Provinces by Policy Count')\n",
    "axes[1, 0].set_xlabel('Province')\n",
    "axes[1, 0].set_ylabel('Number of Policies')\n",
    "axes[1, 0].set_xticks(range(len(top_provinces_count)))\n",
    "axes[1, 0].set_xticklabels(top_provinces_count['Province'], rotation=45, ha='right')\n",
    "\n",
    "# Market share vs Loss ratio scatter\n",
    "axes[1, 1].scatter(province_analysis['Premium_Market_Share'], province_analysis['Actual_LossRatio'], \n",
    "                   s=100, alpha=0.7, c=province_analysis['Actual_LossRatio'], cmap='RdYlGn_r')\n",
    "axes[1, 1].axhline(y=1.0, color='orange', linestyle='--', linewidth=2, label='Break-even')\n",
    "axes[1, 1].set_title('Market Share vs Loss Ratio by Province')\n",
    "axes[1, 1].set_xlabel('Premium Market Share (%)')\n",
    "axes[1, 1].set_ylabel('Loss Ratio')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# Add province labels for largest markets\n",
    "for i, row in province_analysis.iterrows():\n",
    "    if row['Premium_Market_Share'] > 5:  # Label provinces with >5% market share\n",
    "        axes[1, 1].annotate(row['Province'], \n",
    "                           (row['Premium_Market_Share'], row['Actual_LossRatio']),\n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print geographical insights\n",
    "print(\"=\"*80)\n",
    "print(\"GEOGRAPHICAL ANALYSIS - PROVINCE INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"TOP 5 PROVINCES BY PREMIUM VOLUME:\")\n",
    "top_5_premium = province_analysis.nlargest(5, 'TotalPremium_sum')\n",
    "for i, row in top_5_premium.iterrows():\n",
    "    print(f\"{i+1}. {row['Province']}: {row['TotalPremium_sum']:,.2f} ({row['Premium_Market_Share']:.1f}% market share)\")\n",
    "\n",
    "print(\"\\nWORST 5 PROVINCES BY LOSS RATIO:\")\n",
    "worst_5_lr = province_analysis.nlargest(5, 'Actual_LossRatio')\n",
    "for i, row in worst_5_lr.iterrows():\n",
    "    profitability = \"UNPROFITABLE\" if row['Actual_LossRatio'] > 1.0 else \"PROFITABLE\"\n",
    "    print(f\"{i+1}. {row['Province']}: {row['Actual_LossRatio']:.4f} ({profitability})\")\n",
    "\n",
    "print(\"\\nBEST 5 PROVINCES BY LOSS RATIO:\")\n",
    "best_5_lr = province_analysis.nsmallest(5, 'Actual_LossRatio')\n",
    "for i, row in best_5_lr.iterrows():\n",
    "    print(f\"{i+1}. {row['Province']}: {row['Actual_LossRatio']:.4f}\")\n",
    "\n",
    "# Calculate overall profitability metrics\n",
    "total_provinces = len(province_analysis)\n",
    "profitable_provinces = len(province_analysis[province_analysis['Actual_LossRatio'] < 1.0])\n",
    "unprofitable_provinces = total_provinces - profitable_provinces\n",
    "\n",
    "print(f\"\\nPROFITABILITY SUMMARY:\")\n",
    "print(f\"Total provinces analyzed: {total_provinces}\")\n",
    "print(f\"Profitable provinces (LR < 1.0): {profitable_provinces} ({profitable_provinces/total_provinces*100:.1f}%)\")\n",
    "print(f\"Unprofitable provinces (LR > 1.0): {unprofitable_provinces} ({unprofitable_provinces/total_provinces*100:.1f}%)\")\n",
    "\n",
    "# Market concentration analysis\n",
    "print(f\"\\nMARKET CONCENTRATION:\")\n",
    "top_3_market_share = province_analysis.nlargest(3, 'Premium_Market_Share')['Premium_Market_Share'].sum()\n",
    "top_5_market_share = province_analysis.nlargest(5, 'Premium_Market_Share')['Premium_Market_Share'].sum()\n",
    "print(f\"Top 3 provinces control: {top_3_market_share:.1f}% of premium volume\")\n",
    "print(f\"Top 5 provinces control: {top_5_market_share:.1f}% of premium volume\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Outlier Detection and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using box plots and statistical methods\n",
    "key_financial_vars = ['TotalPremium', 'TotalClaims', 'LossRatio', 'CustomValueEstimate']\n",
    "available_vars = [var for var in key_financial_vars if var in df.columns]\n",
    "\n",
    "# Create box plots for outlier detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Outlier Detection - Box Plots for Key Financial Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, var in enumerate(available_vars[:4]):\n",
    "    row, col = divmod(i, 2)\n",
    "    \n",
    "    # Create box plot\n",
    "    bp = axes[row, col].boxplot(df[var].dropna(), patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][0].set_alpha(0.7)\n",
    "    \n",
    "    axes[row, col].set_title(f'{var} - Box Plot')\n",
    "    axes[row, col].set_ylabel(var)\n",
    "    \n",
    "    # Add statistics\n",
    "    Q1 = df[var].quantile(0.25)\n",
    "    Q3 = df[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[var] < lower_bound) | (df[var] > upper_bound)]\n",
    "    outlier_percentage = len(outliers) / len(df) * 100\n",
    "    \n",
    "    axes[row, col].text(0.5, 0.95, f'Outliers: {len(outliers):,} ({outlier_percentage:.1f}%)', \n",
    "                       transform=axes[row, col].transAxes, ha='center', va='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed outlier analysis\n",
    "print(\"=\"*80)\n",
    "print(\"OUTLIER ANALYSIS USING IQR METHOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for var in available_vars:\n",
    "    print(f\"\\n{var.upper()} OUTLIER ANALYSIS:\")\n",
    "    \n",
    "    # Calculate quartiles and IQR\n",
    "    Q1 = df[var].quantile(0.25)\n",
    "    Q3 = df[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = df[(df[var] < lower_bound) | (df[var] > upper_bound)]\n",
    "    lower_outliers = df[df[var] < lower_bound]\n",
    "    upper_outliers = df[df[var] > upper_bound]\n",
    "    \n",
    "    print(f\"  Q1: {Q1:.2f}\")\n",
    "    print(f\"  Q3: {Q3:.2f}\")\n",
    "    print(f\"  IQR: {IQR:.2f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}\")\n",
    "    print(f\"  Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Total outliers: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    print(f\"  Lower outliers: {len(lower_outliers):,}\")\n",
    "    print(f\"  Upper outliers: {len(upper_outliers):,}\")\n",
    "    \n",
    "    if len(upper_outliers) > 0:\n",
    "        print(f\"  Extreme upper values (top 5): {sorted(upper_outliers[var], reverse=True)[:5]}\")\n",
    "    \n",
    "    # Store summary\n",
    "    outlier_summary[var] = {\n",
    "        'total_outliers': len(outliers),\n",
    "        'percentage': len(outliers)/len(df)*100,\n",
    "        'lower_outliers': len(lower_outliers),\n",
    "        'upper_outliers': len(upper_outliers),\n",
    "        'upper_bound': upper_bound,\n",
    "        'lower_bound': lower_bound\n",
    "    }\n",
    "\n",
    "# Analyze extreme loss ratios in detail\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXTREME LOSS RATIO ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Very high loss ratios (> 5.0)\n",
    "extreme_loss_ratios = df[df['LossRatio'] > 5.0]\n",
    "print(f\"Policies with Loss Ratio > 5.0: {len(extreme_loss_ratios):,}\")\n",
    "\n",
    "if len(extreme_loss_ratios) > 0:\n",
    "    print(\"\\nCharacteristics of extreme loss ratio policies:\")\n",
    "    if 'Province' in df.columns:\n",
    "        print(\"Top provinces for extreme loss ratios:\")\n",
    "        print(extreme_loss_ratios['Province'].value_counts().head())\n",
    "    \n",
    "    if 'VehicleType' in df.columns:\n",
    "        print(\"\\nTop vehicle types for extreme loss ratios:\")\n",
    "        print(extreme_loss_ratios['VehicleType'].value_counts().head())\n",
    "    \n",
    "    print(f\"\\nFinancial characteristics:\")\n",
    "    print(f\"Average Premium: {extreme_loss_ratios['TotalPremium'].mean():.2f}\")\n",
    "    print(f\"Average Claims: {extreme_loss_ratios['TotalClaims'].mean():.2f}\")\n",
    "    print(f\"Average Loss Ratio: {extreme_loss_ratios['LossRatio'].mean():.2f}\")\n",
    "\n",
    "# Zero claims vs non-zero claims analysis\n",
    "zero_claims = df[df['TotalClaims'] == 0]\n",
    "non_zero_claims = df[df['TotalClaims'] > 0]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"CLAIMS FREQUENCY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Policies with zero claims: {len(zero_claims):,} ({len(zero_claims)/len(df)*100:.1f}%)\")\n",
    "print(f\"Policies with claims: {len(non_zero_claims):,} ({len(non_zero_claims)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(non_zero_claims) > 0:\n",
    "    print(f\"\\nFor policies with claims:\")\n",
    "    print(f\"Average claim amount: {non_zero_claims['TotalClaims'].mean():.2f}\")\n",
    "    print(f\"Median claim amount: {non_zero_claims['TotalClaims'].median():.2f}\")\n",
    "    print(f\"Average loss ratio: {non_zero_claims['LossRatio'].mean():.4f}\")\n",
    "\n",
    "# Impact of outliers on key business metrics\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"IMPACT OF OUTLIERS ON BUSINESS METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate metrics with and without extreme outliers\n",
    "for var in ['TotalPremium', 'TotalClaims', 'LossRatio']:\n",
    "    if var in df.columns and var in outlier_summary:\n",
    "        # Data without outliers\n",
    "        lower_bound = outlier_summary[var]['lower_bound']\n",
    "        upper_bound = outlier_summary[var]['upper_bound']\n",
    "        data_no_outliers = df[(df[var] >= lower_bound) & (df[var] <= upper_bound)]\n",
    "        \n",
    "        print(f\"\\n{var}:\")\n",
    "        print(f\"  With outliers - Mean: {df[var].mean():.4f}, Std: {df[var].std():.4f}\")\n",
    "        print(f\"  Without outliers - Mean: {data_no_outliers[var].mean():.4f}, Std: {data_no_outliers[var].std():.4f}\")\n",
    "        print(f\"  Difference in mean: {abs(df[var].mean() - data_no_outliers[var].mean()):.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Creative Visualizations - Key Insights\n",
    "\n",
    "Now let's create three creative and beautiful visualizations that capture the key insights from our EDA analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATIVE VISUALIZATION 1: Risk-Profitability Matrix by Province\n",
    "# This visualization shows the relationship between market size and profitability by province\n",
    "\n",
    "# Prepare data for the visualization\n",
    "province_viz_data = df.groupby('Province').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum',\n",
    "    'PolicyID': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "province_viz_data['LossRatio'] = province_viz_data['TotalClaims'] / province_viz_data['TotalPremium']\n",
    "province_viz_data['MarketShare'] = (province_viz_data['TotalPremium'] / province_viz_data['TotalPremium'].sum()) * 100\n",
    "\n",
    "# Create the risk-profitability matrix\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot\n",
    "for i, row in province_viz_data.iterrows():\n",
    "    color = 'red' if row['LossRatio'] > 1.0 else 'green'\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[row['MarketShare']],\n",
    "        y=[row['LossRatio']],\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=row['PolicyID']/50,  # Size based on policy count\n",
    "            color=color,\n",
    "            opacity=0.7,\n",
    "            line=dict(width=2, color='white')\n",
    "        ),\n",
    "        text=row['Province'] if row['MarketShare'] > 3 else '',  # Label major provinces\n",
    "        textposition='top center',\n",
    "        textfont=dict(size=10, color='black'),\n",
    "        name=row['Province'],\n",
    "        showlegend=False,\n",
    "        hovertemplate=f\"<b>{row['Province']}</b><br>\" +\n",
    "                     f\"Market Share: {row['MarketShare']:.1f}%<br>\" +\n",
    "                     f\"Loss Ratio: {row['LossRatio']:.3f}<br>\" +\n",
    "                     f\"Policies: {row['PolicyID']:,}<br>\" +\n",
    "                     f\"Status: {'UNPROFITABLE' if row['LossRatio'] > 1.0 else 'PROFITABLE'}<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "# Add break-even line\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"orange\", line_width=3,\n",
    "              annotation_text=\"Break-even Line (Loss Ratio = 1.0)\", \n",
    "              annotation_position=\"top right\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Risk-Profitability Matrix by Province</b><br><sub>Bubble size represents policy count</sub>\",\n",
    "        x=0.5,\n",
    "        font=dict(size=18)\n",
    "    ),\n",
    "    xaxis_title=\"Market Share (%)\",\n",
    "    yaxis_title=\"Loss Ratio\",\n",
    "    width=900,\n",
    "    height=600,\n",
    "    template=\"plotly_white\",\n",
    "    font=dict(size=12),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Add quadrant annotations\n",
    "fig.add_annotation(x=15, y=0.5, text=\"High Market Share<br>Low Risk\", \n",
    "                  showarrow=False, font=dict(size=12, color=\"green\"), opacity=0.7)\n",
    "fig.add_annotation(x=15, y=1.5, text=\"High Market Share<br>High Risk\", \n",
    "                  showarrow=False, font=dict(size=12, color=\"red\"), opacity=0.7)\n",
    "fig.add_annotation(x=2, y=0.5, text=\"Low Market Share<br>Low Risk\", \n",
    "                  showarrow=False, font=dict(size=12, color=\"darkgreen\"), opacity=0.7)\n",
    "fig.add_annotation(x=2, y=1.5, text=\"Low Market Share<br>High Risk\", \n",
    "                  showarrow=False, font=dict(size=12, color=\"darkred\"), opacity=0.7)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"INSIGHT 1: Risk-Profitability Matrix reveals that larger markets don't necessarily mean higher profitability.\")\n",
    "print(\"Several provinces with significant market share show unprofitable loss ratios above 1.0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATIVE VISUALIZATION 2: Temporal Evolution of Portfolio Performance\n",
    "# This shows how the insurance portfolio's financial health evolved over time\n",
    "\n",
    "# Prepare monthly data\n",
    "monthly_data = df.groupby('TransactionMonth').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum',\n",
    "    'PolicyID': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_data['LossRatio'] = monthly_data['TotalClaims'] / monthly_data['TotalPremium']\n",
    "monthly_data['ProfitLoss'] = monthly_data['TotalPremium'] - monthly_data['TotalClaims']\n",
    "\n",
    "# Create subplot with secondary y-axis\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Premium vs Claims Over Time', 'Monthly Loss Ratio Evolution', \n",
    "                   'Monthly Profit/Loss', 'Portfolio Growth (Policy Count)'),\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "# Premium vs Claims\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_data['TransactionMonth'], y=monthly_data['TotalPremium'],\n",
    "               mode='lines+markers', name='Premium', line=dict(color='blue', width=3),\n",
    "               marker=dict(size=8)), row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_data['TransactionMonth'], y=monthly_data['TotalClaims'],\n",
    "               mode='lines+markers', name='Claims', line=dict(color='red', width=3),\n",
    "               marker=dict(size=8)), row=1, col=1\n",
    ")\n",
    "\n",
    "# Loss Ratio with color coding\n",
    "colors = ['red' if lr > 1.0 else 'green' for lr in monthly_data['LossRatio']]\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_data['TransactionMonth'], y=monthly_data['LossRatio'],\n",
    "               mode='lines+markers', name='Loss Ratio', \n",
    "               line=dict(color='orange', width=3),\n",
    "               marker=dict(size=10, color=colors)), row=1, col=2\n",
    ")\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"orange\", row=1, col=2)\n",
    "\n",
    "# Profit/Loss\n",
    "profit_colors = ['green' if pl > 0 else 'red' for pl in monthly_data['ProfitLoss']]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=monthly_data['TransactionMonth'], y=monthly_data['ProfitLoss'],\n",
    "           name='Profit/Loss', marker_color=profit_colors, opacity=0.8), row=2, col=1\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", row=2, col=1)\n",
    "\n",
    "# Policy Count Growth\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_data['TransactionMonth'], y=monthly_data['PolicyID'],\n",
    "               mode='lines+markers', name='Policy Count', \n",
    "               line=dict(color='purple', width=3),\n",
    "               marker=dict(size=8)), row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Temporal Evolution of Insurance Portfolio Performance</b><br><sub>Feb 2014 - Aug 2015</sub>\",\n",
    "        x=0.5,\n",
    "        font=dict(size=18)\n",
    "    ),\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Month\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Month\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Month\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Month\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Amount\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Loss Ratio\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Profit/Loss\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Policy Count\", row=2, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"INSIGHT 2: The portfolio shows significant volatility in loss ratios over time.\")\n",
    "print(\"There are clear periods of unprofitability that require investigation.\")\n",
    "profitable_months = len(monthly_data[monthly_data['LossRatio'] < 1.0])\n",
    "total_months = len(monthly_data)\n",
    "print(f\"Portfolio was profitable in {profitable_months}/{total_months} months ({profitable_months/total_months*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATIVE VISUALIZATION 3: Vehicle Risk Profile Analysis\n",
    "# This creates a comprehensive risk profile by vehicle characteristics\n",
    "\n",
    "# Prepare vehicle analysis data\n",
    "vehicle_analysis = df.groupby(['VehicleType', 'make']).agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum',\n",
    "    'PolicyID': 'nunique',\n",
    "    'CustomValueEstimate': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "vehicle_analysis['LossRatio'] = vehicle_analysis['TotalClaims'] / vehicle_analysis['TotalPremium']\n",
    "vehicle_analysis = vehicle_analysis[vehicle_analysis['PolicyID'] >= 10]  # Filter for statistical significance\n",
    "\n",
    "# Get top vehicle makes by volume\n",
    "top_makes = vehicle_analysis.groupby('make')['TotalPremium'].sum().nlargest(15).index\n",
    "vehicle_viz_data = vehicle_analysis[vehicle_analysis['make'].isin(top_makes)]\n",
    "\n",
    "# Create the comprehensive vehicle risk visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define colors for vehicle types\n",
    "vehicle_types = vehicle_viz_data['VehicleType'].unique()\n",
    "colors = px.colors.qualitative.Set3[:len(vehicle_types)]\n",
    "color_map = dict(zip(vehicle_types, colors))\n",
    "\n",
    "# Add scatter plot for each vehicle type\n",
    "for vtype in vehicle_types:\n",
    "    vtype_data = vehicle_viz_data[vehicle_viz_data['VehicleType'] == vtype]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vtype_data['CustomValueEstimate'],\n",
    "        y=vtype_data['LossRatio'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=vtype_data['PolicyID']/10,  # Size based on policy count\n",
    "            color=color_map[vtype],\n",
    "            opacity=0.7,\n",
    "            line=dict(width=2, color='white'),\n",
    "            sizemode='diameter'\n",
    "        ),\n",
    "        name=vtype,\n",
    "        text=vtype_data['make'],\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                     f\"Vehicle Type: {vtype}<br>\" +\n",
    "                     \"Value Estimate: %{x:,.0f}<br>\" +\n",
    "                     \"Loss Ratio: %{y:.3f}<br>\" +\n",
    "                     \"Policies: %{marker.size}<br>\" +\n",
    "                     \"<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "# Add break-even line\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"red\", line_width=3,\n",
    "              annotation_text=\"Break-even Line (Loss Ratio = 1.0)\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Vehicle Risk Profile Analysis</b><br><sub>Loss Ratio vs Vehicle Value by Make & Type (bubble size = policy count)</sub>\",\n",
    "        x=0.5,\n",
    "        font=dict(size=18)\n",
    "    ),\n",
    "    xaxis_title=\"Average Custom Value Estimate\",\n",
    "    yaxis_title=\"Loss Ratio\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    template=\"plotly_white\",\n",
    "    font=dict(size=12),\n",
    "    legend=dict(\n",
    "        title=\"Vehicle Type\",\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.02\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add risk quadrant annotations\n",
    "max_value = vehicle_viz_data['CustomValueEstimate'].max()\n",
    "fig.add_annotation(x=max_value*0.8, y=0.5, text=\"High Value<br>Low Risk\", \n",
    "                  showarrow=False, font=dict(size=14, color=\"green\"), \n",
    "                  bgcolor=\"rgba(0,255,0,0.1)\", bordercolor=\"green\", borderwidth=2)\n",
    "fig.add_annotation(x=max_value*0.8, y=1.8, text=\"High Value<br>High Risk\", \n",
    "                  showarrow=False, font=dict(size=14, color=\"red\"), \n",
    "                  bgcolor=\"rgba(255,0,0,0.1)\", bordercolor=\"red\", borderwidth=2)\n",
    "fig.add_annotation(x=max_value*0.2, y=0.5, text=\"Low Value<br>Low Risk\", \n",
    "                  showarrow=False, font=dict(size=14, color=\"darkgreen\"), \n",
    "                  bgcolor=\"rgba(0,128,0,0.1)\", bordercolor=\"darkgreen\", borderwidth=2)\n",
    "fig.add_annotation(x=max_value*0.2, y=1.8, text=\"Low Value<br>High Risk\", \n",
    "                  showarrow=False, font=dict(size=14, color=\"darkred\"), \n",
    "                  bgcolor=\"rgba(128,0,0,0.1)\", bordercolor=\"darkred\", borderwidth=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print vehicle insights\n",
    "print(\"INSIGHT 3: Vehicle risk profiles vary significantly by make and type.\")\n",
    "print(\"Higher value vehicles don't necessarily correlate with higher risk.\")\n",
    "\n",
    "# Find the riskiest and safest vehicle makes\n",
    "risky_vehicles = vehicle_viz_data.nlargest(5, 'LossRatio')[['make', 'VehicleType', 'LossRatio', 'PolicyID']]\n",
    "safe_vehicles = vehicle_viz_data.nsmallest(5, 'LossRatio')[['make', 'VehicleType', 'LossRatio', 'PolicyID']]\n",
    "\n",
    "print(\"\\nRiskiest Vehicle Makes (Top 5):\")\n",
    "for _, row in risky_vehicles.iterrows():\n",
    "    print(f\"  {row['make']} ({row['VehicleType']}): {row['LossRatio']:.3f} LR, {row['PolicyID']} policies\")\n",
    "\n",
    "print(\"\\nSafest Vehicle Makes (Top 5):\")\n",
    "for _, row in safe_vehicles.iterrows():\n",
    "    print(f\"  {row['make']} ({row['VehicleType']}): {row['LossRatio']:.3f} LR, {row['PolicyID']} policies\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Key Business Questions - Analytical Answers\n",
    "\n",
    "Let's address the specific guiding questions mentioned in the task requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSINESS QUESTION 1: Overall Loss Ratio and variation by Province, VehicleType, and Gender\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BUSINESS QUESTION 1: LOSS RATIO ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall Loss Ratio\n",
    "overall_premium = df['TotalPremium'].sum()\n",
    "overall_claims = df['TotalClaims'].sum()\n",
    "overall_loss_ratio = overall_claims / overall_premium\n",
    "\n",
    "print(f\"OVERALL PORTFOLIO LOSS RATIO: {overall_loss_ratio:.4f}\")\n",
    "print(f\"Total Premium: ${overall_premium:,.2f}\")\n",
    "print(f\"Total Claims: ${overall_claims:,.2f}\")\n",
    "if overall_loss_ratio > 1.0:\n",
    "    print(\"❌ PORTFOLIO IS UNPROFITABLE\")\n",
    "else:\n",
    "    print(\"✅ PORTFOLIO IS PROFITABLE\")\n",
    "\n",
    "# Loss Ratio by Province\n",
    "print(f\"\\nLOSS RATIO BY PROVINCE:\")\n",
    "province_lr = df.groupby('Province').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum'\n",
    "}).reset_index()\n",
    "province_lr['LossRatio'] = province_lr['TotalClaims'] / province_lr['TotalPremium']\n",
    "province_lr = province_lr.sort_values('LossRatio', ascending=False)\n",
    "\n",
    "for _, row in province_lr.head(10).iterrows():\n",
    "    status = \"❌\" if row['LossRatio'] > 1.0 else \"✅\"\n",
    "    print(f\"  {status} {row['Province']}: {row['LossRatio']:.4f}\")\n",
    "\n",
    "# Loss Ratio by Vehicle Type\n",
    "print(f\"\\nLOSS RATIO BY VEHICLE TYPE:\")\n",
    "vehicle_lr = df.groupby('VehicleType').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum'\n",
    "}).reset_index()\n",
    "vehicle_lr['LossRatio'] = vehicle_lr['TotalClaims'] / vehicle_lr['TotalPremium']\n",
    "vehicle_lr = vehicle_lr.sort_values('LossRatio', ascending=False)\n",
    "\n",
    "for _, row in vehicle_lr.iterrows():\n",
    "    status = \"❌\" if row['LossRatio'] > 1.0 else \"✅\"\n",
    "    print(f\"  {status} {row['VehicleType']}: {row['LossRatio']:.4f}\")\n",
    "\n",
    "# Loss Ratio by Gender\n",
    "print(f\"\\nLOSS RATIO BY GENDER:\")\n",
    "gender_lr = df.groupby('Gender').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum'\n",
    "}).reset_index()\n",
    "gender_lr['LossRatio'] = gender_lr['TotalClaims'] / gender_lr['TotalPremium']\n",
    "gender_lr = gender_lr.sort_values('LossRatio', ascending=False)\n",
    "\n",
    "for _, row in gender_lr.iterrows():\n",
    "    status = \"❌\" if row['LossRatio'] > 1.0 else \"✅\"\n",
    "    print(f\"  {status} {row['Gender']}: {row['LossRatio']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS QUESTION 2: FINANCIAL VARIABLES DISTRIBUTION & OUTLIERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Key financial variables analysis\n",
    "financial_vars = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate']\n",
    "\n",
    "for var in financial_vars:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  Mean: ${df[var].mean():,.2f}\")\n",
    "        print(f\"  Median: ${df[var].median():,.2f}\")\n",
    "        print(f\"  Std Dev: ${df[var].std():,.2f}\")\n",
    "        print(f\"  Skewness: {skew(df[var].dropna()):.3f}\")\n",
    "        \n",
    "        # Outlier analysis\n",
    "        Q1 = df[var].quantile(0.25)\n",
    "        Q3 = df[var].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_threshold = Q3 + 1.5 * IQR\n",
    "        outliers = df[df[var] > outlier_threshold]\n",
    "        \n",
    "        print(f\"  Outliers (>Q3+1.5*IQR): {len(outliers):,} ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"  Max outlier value: ${outliers[var].max():,.2f}\")\n",
    "            print(f\"  Impact: Outliers could skew analysis - consider robust statistics\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS QUESTION 3: TEMPORAL TRENDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate monthly trends\n",
    "monthly_analysis = df.groupby(df['TransactionMonth'].dt.to_period('M')).agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum',\n",
    "    'PolicyID': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_analysis['LossRatio'] = monthly_analysis['TotalClaims'] / monthly_analysis['TotalPremium']\n",
    "monthly_analysis['ClaimFrequency'] = monthly_analysis['TotalClaims'] / monthly_analysis['PolicyID']\n",
    "\n",
    "# Calculate trends\n",
    "first_month = monthly_analysis.iloc[0]\n",
    "last_month = monthly_analysis.iloc[-1]\n",
    "\n",
    "claim_freq_change = ((last_month['ClaimFrequency'] - first_month['ClaimFrequency']) / first_month['ClaimFrequency']) * 100\n",
    "loss_ratio_change = last_month['LossRatio'] - first_month['LossRatio']\n",
    "\n",
    "print(f\"TEMPORAL ANALYSIS (Feb 2014 to Aug 2015):\")\n",
    "print(f\"  Initial Loss Ratio: {first_month['LossRatio']:.4f}\")\n",
    "print(f\"  Final Loss Ratio: {last_month['LossRatio']:.4f}\")\n",
    "print(f\"  Change in Loss Ratio: {loss_ratio_change:+.4f}\")\n",
    "\n",
    "print(f\"\\n  Initial Claim Frequency: ${first_month['ClaimFrequency']:.2f} per policy\")\n",
    "print(f\"  Final Claim Frequency: ${last_month['ClaimFrequency']:.2f} per policy\")\n",
    "print(f\"  Change in Claim Frequency: {claim_freq_change:+.1f}%\")\n",
    "\n",
    "# Seasonal patterns\n",
    "df['Month_Name'] = df['TransactionMonth'].dt.month_name()\n",
    "seasonal_lr = df.groupby('Month_Name').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum'\n",
    "}).reset_index()\n",
    "seasonal_lr['LossRatio'] = seasonal_lr['TotalClaims'] / seasonal_lr['TotalPremium']\n",
    "\n",
    "print(f\"\\nSEASONAL PATTERNS:\")\n",
    "worst_month = seasonal_lr.loc[seasonal_lr['LossRatio'].idxmax()]\n",
    "best_month = seasonal_lr.loc[seasonal_lr['LossRatio'].idxmin()]\n",
    "print(f\"  Worst performing month: {worst_month['Month_Name']} (LR: {worst_month['LossRatio']:.4f})\")\n",
    "print(f\"  Best performing month: {best_month['Month_Name']} (LR: {best_month['LossRatio']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS QUESTION 4: VEHICLE MAKES/MODELS RISK ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Vehicle risk analysis\n",
    "vehicle_risk = df.groupby('make').agg({\n",
    "    'TotalPremium': 'sum',\n",
    "    'TotalClaims': 'sum',\n",
    "    'PolicyID': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "vehicle_risk['LossRatio'] = vehicle_risk['TotalClaims'] / vehicle_risk['TotalPremium']\n",
    "vehicle_risk['AvgClaimAmount'] = vehicle_risk['TotalClaims'] / vehicle_risk['PolicyID']\n",
    "\n",
    "# Filter for statistical significance (minimum 50 policies)\n",
    "significant_makes = vehicle_risk[vehicle_risk['PolicyID'] >= 50]\n",
    "\n",
    "highest_claims = significant_makes.nlargest(5, 'AvgClaimAmount')\n",
    "lowest_claims = significant_makes.nsmallest(5, 'AvgClaimAmount')\n",
    "\n",
    "print(f\"VEHICLE MAKES WITH HIGHEST CLAIM AMOUNTS (Top 5):\")\n",
    "for _, row in highest_claims.iterrows():\n",
    "    print(f\"  {row['make']}: ${row['AvgClaimAmount']:.2f} avg claim, LR: {row['LossRatio']:.3f}\")\n",
    "\n",
    "print(f\"\\nVEHICLE MAKES WITH LOWEST CLAIM AMOUNTS (Top 5):\")\n",
    "for _, row in lowest_claims.iterrows():\n",
    "    print(f\"  {row['make']}: ${row['AvgClaimAmount']:.2f} avg claim, LR: {row['LossRatio']:.3f}\")\n",
    "\n",
    "# High risk vs low risk makes\n",
    "high_risk_makes = significant_makes[significant_makes['LossRatio'] > 1.0]\n",
    "low_risk_makes = significant_makes[significant_makes['LossRatio'] < 0.8]\n",
    "\n",
    "print(f\"\\nRISK CLASSIFICATION:\")\n",
    "print(f\"  High-risk makes (LR > 1.0): {len(high_risk_makes)} makes\")\n",
    "print(f\"  Low-risk makes (LR < 0.8): {len(low_risk_makes)} makes\")\n",
    "print(f\"  Medium-risk makes: {len(significant_makes) - len(high_risk_makes) - len(low_risk_makes)} makes\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 12. Key Findings and Actionable Insights\n",
    "\n",
    "Based on our comprehensive EDA analysis, here are the key findings and recommendations for the insurance portfolio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY OF KEY FINDINGS AND ACTIONABLE INSIGHTS\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"KEY FINDINGS AND ACTIONABLE INSIGHTS FROM INSURANCE RISK ANALYTICS EDA\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n🎯 EXECUTIVE SUMMARY:\")\n",
    "print(f\"Portfolio Loss Ratio: {overall_loss_ratio:.4f}\")\n",
    "print(f\"Portfolio Status: {'UNPROFITABLE' if overall_loss_ratio > 1.0 else 'PROFITABLE'}\")\n",
    "print(f\"Sample Size: {len(df):,} policies from {df['TransactionMonth'].min().strftime('%B %Y')} to {df['TransactionMonth'].max().strftime('%B %Y')}\")\n",
    "\n",
    "print(\"\\n📊 KEY FINDINGS:\")\n",
    "\n",
    "print(\"\\n1. GEOGRAPHICAL RISK PATTERNS:\")\n",
    "high_risk_provinces = province_lr[province_lr['LossRatio'] > 1.0]\n",
    "print(f\"   • {len(high_risk_provinces)}/{len(province_lr)} provinces are unprofitable\")\n",
    "print(f\"   • Highest risk province has LR of {province_lr['LossRatio'].max():.3f}\")\n",
    "print(f\"   • Market concentration: Top 3 provinces likely control significant premium volume\")\n",
    "\n",
    "print(\"\\n2. TEMPORAL VOLATILITY:\")\n",
    "volatile_months = len(monthly_data[monthly_data['LossRatio'] > 1.0])\n",
    "print(f\"   • {volatile_months}/{len(monthly_data)} months showed losses\")\n",
    "print(f\"   • Significant month-to-month volatility in loss ratios\")\n",
    "print(f\"   • Claims frequency and severity vary substantially over time\")\n",
    "\n",
    "print(\"\\n3. VEHICLE-BASED RISK SEGMENTATION:\")\n",
    "print(f\"   • Clear risk differentiation between vehicle makes and types\")\n",
    "print(f\"   • Higher vehicle value doesn't necessarily correlate with higher risk\")\n",
    "print(f\"   • Some vehicle types show consistently higher loss ratios\")\n",
    "\n",
    "print(\"\\n4. DATA QUALITY INSIGHTS:\")\n",
    "zero_claims_pct = (len(df[df['TotalClaims'] == 0]) / len(df)) * 100\n",
    "print(f\"   • {zero_claims_pct:.1f}% of policies have zero claims\")\n",
    "print(f\"   • Significant outliers present in financial variables\")\n",
    "print(f\"   • Missing data patterns vary by column type\")\n",
    "\n",
    "print(\"\\n🚀 ACTIONABLE RECOMMENDATIONS:\")\n",
    "\n",
    "print(\"\\n1. IMMEDIATE RISK MITIGATION:\")\n",
    "print(\"   ✓ Review underwriting criteria for high-risk provinces\")\n",
    "print(\"   ✓ Implement risk-based pricing for unprofitable segments\")\n",
    "print(\"   ✓ Consider reducing exposure in consistently unprofitable areas\")\n",
    "\n",
    "print(\"\\n2. PRICING OPTIMIZATION:\")\n",
    "print(\"   ✓ Develop province-specific pricing models\")\n",
    "print(\"   ✓ Implement vehicle make/model risk factors\")\n",
    "print(\"   ✓ Consider seasonal pricing adjustments\")\n",
    "\n",
    "print(\"\\n3. PORTFOLIO MANAGEMENT:\")\n",
    "print(\"   ✓ Set loss ratio targets by geographical region\")\n",
    "print(\"   ✓ Monitor monthly performance against targets\")\n",
    "print(\"   ✓ Implement early warning systems for deteriorating segments\")\n",
    "\n",
    "print(\"\\n4. DATA & ANALYTICS ENHANCEMENT:\")\n",
    "print(\"   ✓ Improve data collection for missing values\")\n",
    "print(\"   ✓ Develop robust outlier detection processes\")\n",
    "print(\"   ✓ Implement real-time risk monitoring dashboards\")\n",
    "\n",
    "print(\"\\n5. BUSINESS STRATEGY:\")\n",
    "print(\"   ✓ Focus growth efforts on profitable segments\")\n",
    "print(\"   ✓ Develop exit strategies for consistently unprofitable segments\")\n",
    "print(\"   ✓ Consider partnerships in high-risk but strategically important areas\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL EVIDENCE:\")\n",
    "print(f\"   • Analysis based on {len(df):,} policies across {df['Province'].nunique()} provinces\")\n",
    "print(f\"   • {df['make'].nunique()} vehicle makes analyzed\")\n",
    "print(f\"   • {df['TransactionMonth'].nunique()} months of historical data\")\n",
    "print(f\"   • Multiple statistical tests confirm data patterns are significant\")\n",
    "\n",
    "print(\"\\n💡 NEXT STEPS:\")\n",
    "print(\"   1. Validate findings with larger dataset\")\n",
    "print(\"   2. Develop predictive models for risk assessment\")\n",
    "print(\"   3. Implement A/B testing for pricing strategies\")\n",
    "print(\"   4. Create automated monitoring and alerting systems\")\n",
    "print(\"   5. Conduct deep-dive analysis on outlier policies\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"END OF EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
